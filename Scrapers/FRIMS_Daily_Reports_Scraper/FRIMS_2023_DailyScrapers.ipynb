{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3728c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import camelot\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import pygsheets\n",
    "from datetime import date, timedelta, datetime\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing as mp\n",
    "from multiprocessing.pool import ThreadPool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d798b8f",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "* [Functions to be used](#functions)\n",
    "* [Download PDFs](#download)\n",
    "* [Scraper for infrastructure damage tables](#infradamages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934fc316",
   "metadata": {},
   "source": [
    "## Functions <a class=\"anchor\" id=\"functions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a34c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequence Matcher helps us get the metric that measures how two strings are matching\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "#We will write a function that gives us matching score between two strings a and b. Higher the score,better the match\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81dbf4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One FRIMS PDF has multiple tables that have to be scraped.\n",
    "## The following functions are used to isolate the tables based on their categories. \n",
    "def get_table_start_index(FRIMS_DF, slug_list):\n",
    "    '''\n",
    "    :param FRIMS_DF: The FRIMS Data Frame of a particular date.\n",
    "    :param slug_list: A list of keywords used to identify a particular table in the PDF.\n",
    "    \n",
    "    :return: Returns the index of the first row of the intended table.\n",
    "    '''\n",
    "    TABLE_START_INDEX = FRIMS_DF[FRIMS_DF.iloc[:,0].isin(slug_list)].index.values[0]\n",
    "    return TABLE_START_INDEX\n",
    "\n",
    "def get_table_end_index(FRIMS_DF, TABLE_START_INDEX):\n",
    "    '''\n",
    "    :param FRIMS_DF: The FRIMS Data Frame of a particular date.\n",
    "    :param TABLE_START_INDEX: Once the index of a table's first row is found, it is passed into this function.\n",
    "    \n",
    "    :return: Returns the index of the last row of the intended table.\n",
    "    '''\n",
    "    for index,row in FRIMS_DF[TABLE_START_INDEX+1:].fillna('').iterrows():\n",
    "        if row[0]=='':\n",
    "            continue\n",
    "        else:\n",
    "            TABLE_END_INDEX = index\n",
    "            return TABLE_END_INDEX\n",
    "            break\n",
    "    return TABLE_START_INDEX+100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3070b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_infra_damages_data(FRIMS_DF, TABLE_START_INDEX, TABLE_END_INDEX):\n",
    "    '''\n",
    "    :param FRIMS_DF: The FRIMS Data Frame of a particular date.\n",
    "    :param TABLE_START_INDEX: Once the index of a table's first row is found, it is passed into this function.\n",
    "    :param TABLE_END_INDEX: Once the index of a table's last row is found, it is passed into this function.\n",
    "    \n",
    "    :return: Returns the filtered table between the indices passed, after cleaning it.\n",
    "    '''\n",
    "    FRIMS_INFRA_DAMAGES_DF = FRIMS_DF.loc[TABLE_START_INDEX:TABLE_END_INDEX-1,:].reset_index(drop=True)\n",
    "    FRIMS_INFRA_DAMAGES_DF = FRIMS_INFRA_DAMAGES_DF.replace(r'\\n','',regex=True)\n",
    "    \n",
    "    FRIMS_INFRA_DAMAGES_DF.columns=FRIMS_INFRA_DAMAGES_DF.iloc[0].str.replace(r'\\n','',regex=True)\n",
    "    FRIMS_INFRA_DAMAGES_DF = FRIMS_INFRA_DAMAGES_DF.loc[1:,:]\n",
    "    \n",
    "    return FRIMS_INFRA_DAMAGES_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad5f917",
   "metadata": {},
   "source": [
    "## Download PDFs <a class=\"anchor\" id=\"download\"></a>\n",
    "\n",
    "Download all PDFs from [FRIMS](http://www.asdma.gov.in/reports.html) portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf924bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in range(6,7):\n",
    "    if month in [8,10]:\n",
    "        max_date=32\n",
    "        min_date=1\n",
    "    elif month in [6]:\n",
    "        max_date=31\n",
    "        min_date=1\n",
    "\n",
    "\n",
    "    for day in range(min_date,max_date):\n",
    "        date = str(day)+'-'+str(month)+'-'+'2023'\n",
    "        if type(date)==str:\n",
    "            date = datetime.strptime(date, '%d-%m-%Y').date()\n",
    "        else:\n",
    "            date = date + timedelta(days=-1)\n",
    "        \n",
    "        if date.month<10:\n",
    "            date_month = '0'+str(date.month)\n",
    "        else:\n",
    "            date_month = str(date.month)\n",
    "        \n",
    "        if date.day<10:\n",
    "            date_day = '0'+str(date.day)\n",
    "        else:\n",
    "            date_day = str(date.day)\n",
    "        \n",
    "        date_string = date_day+'.'+date_month+'.'+str(date.year)\n",
    "        print(date_string)\n",
    "        \n",
    "        daily_report_url = 'https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_'+date_string+'.pdf'\n",
    "        print(daily_report_url)\n",
    "        urllib.request.urlretrieve(daily_report_url, r\"FRIMS_Reports_2023/FRIMS_\"+date_string+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9702c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "frims_pdfs = glob.glob('FRIMS_Reports_2023/*.pdf')\n",
    "for pdf in frims_pdfs:\n",
    "    print(pdf)\n",
    "    date_string = pdf.split('FRIMS_')[-1].split('.pdf')[0]\n",
    "    tables = camelot.read_pdf(pdf,pages='all')\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(0,len(tables)):\n",
    "        df = pd.concat([df,tables[i].df],axis=0, ignore_index=True)\n",
    "    \n",
    "    df.to_csv(\"FRIMS_Reports_2023/FRIMS_\"+date_string+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3354969",
   "metadata": {},
   "source": [
    "# INFRA DAMAGES <a class=\"anchor\" id=\"infradamages\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "060df38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for file in glob.glob('FRIMS_Reports_2023/FRIMS_*.pdf'):\n",
    "    date = file.split('FRIMS_')[-1].split('.pdf')[0]\n",
    "    dates.append(date)\n",
    "\n",
    "issue_dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa83751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slug_lists = [['infrastructure damaged - road','infrastructure damaged - roads'],\n",
    "              ['infrastructure damaged - embankments affected','infrastructure damaged - embankment affected'],\n",
    "              ['infrastructure damaged - bridge','infrastructure damaged - bridges'],\n",
    "              ['infrastructure damaged - embankments breached','infrastructure damaged - embankment breached'],\n",
    "              ]\n",
    "\n",
    "folder_slug_dict = dict()\n",
    "folder_slug_dict[0] ='FRIMS_ROADS_DAMAGED'\n",
    "folder_slug_dict[1] ='FRIMS_EMBANKMENTS_AFFECTED'\n",
    "folder_slug_dict[2] ='FRIMS_BRIDGES_DAMAGED'\n",
    "folder_slug_dict[3] ='FRIMS_EMBANKMENTS_BREACHED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5f67c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_issue_dates = []\n",
    "embankment_affected_issue_dates = []\n",
    "bridge_issue_dates = []\n",
    "embankment_breached_issue_dates = []\n",
    "\n",
    "issues_dates = [road_issue_dates,\n",
    "                embankment_affected_issue_dates,\n",
    "               bridge_issue_dates,\n",
    "                embankment_breached_issue_dates,\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad32ccf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  07.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  07.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  07.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  07.06.2023\n",
      "----\n",
      "24.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "06.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  06.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  06.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  06.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  06.06.2023\n",
      "----\n",
      "16.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  16-06-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "10.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  10.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  10.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  10.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  10.06.2023\n",
      "----\n",
      "18.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  18-06-2023\n",
      "----\n",
      "05.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  05.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  05.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  05.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  05.06.2023\n",
      "----\n",
      "08.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  08.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  08.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  08.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  08.06.2023\n",
      "----\n",
      "04.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  04.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  04.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  04.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  04.06.2023\n",
      "----\n",
      "23.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "21.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "03.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  03.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  03.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  03.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  03.06.2023\n",
      "----\n",
      "14.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8144/1982773773.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "09.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  09.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  09.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  09.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  09.06.2023\n",
      "----\n",
      "15.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  15-06-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "01.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  01.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  01.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  01.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  01.06.2023\n",
      "----\n",
      "13.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  13-06-2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  13-06-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  13-06-2023\n",
      "----\n",
      "19.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  19-06-2023\n",
      "----\n",
      "20.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "02.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  02.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  02.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  02.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  02.06.2023\n",
      "----\n",
      "25.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "11.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  11-06-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "22.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "17.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "12.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  12-06-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for date in dates:    \n",
    "    print(date)\n",
    "    FRIMS_csv_file = r\"FRIMS_Reports_2023/FRIMS_\"+date+\".csv\"\n",
    "    \n",
    "    \n",
    "    FRIMS_DF = pd.read_csv(FRIMS_csv_file)\n",
    "    \n",
    "    FRIMS_DF.iloc[:,0] = FRIMS_DF.iloc[:,0].str.replace(r'\\n','',regex=True)\n",
    "    FRIMS_DF.iloc[:,0] = FRIMS_DF.iloc[:,0].str.lower()\n",
    "    \n",
    "    for list_number, slug_list in enumerate(slug_lists):\n",
    "        folder_slug = folder_slug_dict[list_number]\n",
    "        print(folder_slug)\n",
    "        \n",
    "        try:\n",
    "            TABLE_START_INDEX = get_table_start_index(FRIMS_DF, slug_list)\n",
    "        except:\n",
    "            issues_dates[list_number].append(date)\n",
    "            print('Issue with infra damages table - Row header across multiple pages')\n",
    "            print(\"----\")\n",
    "            continue\n",
    "            \n",
    "        if folder_slug=='FRIMS_URBANFLOOD':\n",
    "            TABLE_END_INDEX = TABLE_START_INDEX+100\n",
    "        else:\n",
    "            TABLE_END_INDEX = get_table_end_index(FRIMS_DF, TABLE_START_INDEX)\n",
    "\n",
    "        if TABLE_END_INDEX-1 <= TABLE_START_INDEX:\n",
    "            print(\"No data for: \",date)\n",
    "            #done_dates.append(date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        \n",
    "        try:   \n",
    "            FRIMS_INFRA_DAMAGES_DF = extract_infra_damages_data(FRIMS_DF, TABLE_START_INDEX, TABLE_END_INDEX-1)\n",
    "        except:\n",
    "            print(\"No dataa for: \",date)\n",
    "            #issues_dates[list_number].append(date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            col_name = FRIMS_INFRA_DAMAGES_DF.columns[1]\n",
    "            FRIMS_INFRA_DAMAGES_DF[col_name] = FRIMS_INFRA_DAMAGES_DF[col_name].replace('',None).fillna(method='ffill')\n",
    "            g = FRIMS_INFRA_DAMAGES_DF.groupby(col_name)['Details'].transform(lambda x: ' '.join(x))\n",
    "        except:\n",
    "            print('Issues with cleaning and combining')\n",
    "            issues_dates[list_number].append(date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "            \n",
    "        FRIMS_INFRA_DAMAGES_DF['Details'] = g\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED = FRIMS_INFRA_DAMAGES_DF.drop_duplicates()\n",
    "        \n",
    "        \n",
    "        date = date.replace('.','-')\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED = FRIMS_INFRA_DAMAGES_DF_CLEANED[['Date', col_name, 'Number', 'Details']]\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED.columns = ['Date', 'District', 'Number', 'Details']\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED = FRIMS_INFRA_DAMAGES_DF_CLEANED[FRIMS_INFRA_DAMAGES_DF_CLEANED['Number'].notna()]\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED.reset_index(drop=True).to_csv(r'Data_2023/Scraped Data/'+folder_slug+r'/'+folder_slug+'_'+str(date)+'.csv', index=False)\n",
    "        print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19c824ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FRIMS_ROADS_DAMAGED</th>\n",
       "      <th>FRIMS_EMBANKMENTS_AFFECTED</th>\n",
       "      <th>FRIMS_BRIDGES_DAMAGED</th>\n",
       "      <th>FRIMS_EMBANKMENTS_BREACHED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>24-06-2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FRIMS_ROADS_DAMAGED FRIMS_EMBANKMENTS_AFFECTED FRIMS_BRIDGES_DAMAGED  \\\n",
       "0                None                       None                  None   \n",
       "\n",
       "  FRIMS_EMBANKMENTS_BREACHED  \n",
       "0                 24-06-2023  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_df = pd.DataFrame(issues_dates).T\n",
    "issues_df.columns = folder_slug_dict.values()\n",
    "issues_df\n",
    "\n",
    "#Add this manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e81aeec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder_slug in ['FRIMS_EMBANKMENTS_BREACHED']:\n",
    "    scraped_files_daily = glob.glob(r'Data_2023/Scraped Data/{}/*.csv'.format(folder_slug))\n",
    "    \n",
    "    dfs = []\n",
    "    for file in scraped_files_daily:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    FRIMS_DAMAGES = pd.concat(dfs)\n",
    "    FRIMS_DAMAGES['Date'] = pd.to_datetime(FRIMS_DAMAGES['Date'],format='%d-%m-%Y')\n",
    "    FRIMS_DAMAGES = FRIMS_DAMAGES.sort_values(by='Date')\n",
    "    FRIMS_DAMAGES.drop_duplicates().dropna().to_csv('Data_2023/Cleaned Data/{}_MASTER_2023.csv'.format(folder_slug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bb4a4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>District</th>\n",
       "      <th>Number</th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-11</td>\n",
       "      <td>Biswanath</td>\n",
       "      <td>1</td>\n",
       "      <td>Gohpur - Kukurjan River Embankment near about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>Lakhimpur</td>\n",
       "      <td>1</td>\n",
       "      <td>Nowboicha - Embankment at Pabha Nadi River nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>Darrang</td>\n",
       "      <td>3</td>\n",
       "      <td>Mangaldoi - Afflux Bund at Noanadi Kachia Bund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>Biswanath</td>\n",
       "      <td>1</td>\n",
       "      <td>Gohpur - Dubia River Embankments is breached f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-14</td>\n",
       "      <td>Lakhimpur</td>\n",
       "      <td>2</td>\n",
       "      <td>Nowboicha - Breached occurred at Singra River ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-15</td>\n",
       "      <td>Goalpara</td>\n",
       "      <td>1</td>\n",
       "      <td>Matia - Dohapara Bamunpara Bandh | Bamunpara |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-16</td>\n",
       "      <td>Lakhimpur</td>\n",
       "      <td>2</td>\n",
       "      <td>Narayanpur - Farm bundh L/S-175 m R/S-175 m | ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-16</td>\n",
       "      <td>Udalguri</td>\n",
       "      <td>2</td>\n",
       "      <td>Harisinga - No. 2 Singrimari Suklai river emba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-17</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>1</td>\n",
       "      <td>Chariduar - 1 no embankment breached on DTD 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-17</td>\n",
       "      <td>Darrang</td>\n",
       "      <td>2</td>\n",
       "      <td>Mangaldoi - Approach Road in Noanadi Kachia Bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-17</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>1</td>\n",
       "      <td>Kampur - Premajaan Embankment at Saibuk Gaon |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-17</td>\n",
       "      <td>Udalguri</td>\n",
       "      <td>1</td>\n",
       "      <td>Kalaigaon - Embankment at Majarchuba in the L/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-20</td>\n",
       "      <td>Udalguri</td>\n",
       "      <td>1</td>\n",
       "      <td>Harisinga - Dahalahabi embankment | Dahalahabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-21</td>\n",
       "      <td>Baksa</td>\n",
       "      <td>3</td>\n",
       "      <td>Barama - Breach occurred on L/B of Mora Paglad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-21</td>\n",
       "      <td>Nalbari</td>\n",
       "      <td>1</td>\n",
       "      <td>Tihu - ROAD CUM EMBANMENT,R/B MORA PAGOLDIA RI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>Darrang</td>\n",
       "      <td>1</td>\n",
       "      <td>Mangaldoi - Breached at u/s afflux bund cum ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>Bajali</td>\n",
       "      <td>7</td>\n",
       "      <td>Bajali - Pahumara river breached at left bank ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>Biswanath</td>\n",
       "      <td>1</td>\n",
       "      <td>Gohpur - Chatrang river R/Bank embankment brea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>Nalbari</td>\n",
       "      <td>1</td>\n",
       "      <td>Nalbari - Pagaldia river at Nalbari sonkuriha ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-23</td>\n",
       "      <td>Biswanath</td>\n",
       "      <td>1</td>\n",
       "      <td>Gohpur - Chatrang P&amp;R D Bund | At L/Bank or Ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-25</td>\n",
       "      <td>Darrang</td>\n",
       "      <td>3</td>\n",
       "      <td>Mangaldoi - CM Dutta | At village Mollapara | ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   District  Number  \\\n",
       "0 2023-06-11  Biswanath       1   \n",
       "2 2023-06-12  Lakhimpur       1   \n",
       "1 2023-06-12    Darrang       3   \n",
       "0 2023-06-12  Biswanath       1   \n",
       "0 2023-06-14  Lakhimpur       2   \n",
       "0 2023-06-15   Goalpara       1   \n",
       "0 2023-06-16  Lakhimpur       2   \n",
       "1 2023-06-16   Udalguri       2   \n",
       "2 2023-06-17   Sonitpur       1   \n",
       "0 2023-06-17    Darrang       2   \n",
       "1 2023-06-17     Nagaon       1   \n",
       "3 2023-06-17   Udalguri       1   \n",
       "0 2023-06-20   Udalguri       1   \n",
       "0 2023-06-21      Baksa       3   \n",
       "1 2023-06-21    Nalbari       1   \n",
       "2 2023-06-22    Darrang       1   \n",
       "0 2023-06-22     Bajali       7   \n",
       "1 2023-06-22  Biswanath       1   \n",
       "3 2023-06-22    Nalbari       1   \n",
       "0 2023-06-23  Biswanath       1   \n",
       "0 2023-06-25    Darrang       3   \n",
       "\n",
       "                                             Details  \n",
       "0  Gohpur - Kukurjan River Embankment near about ...  \n",
       "2  Nowboicha - Embankment at Pabha Nadi River nea...  \n",
       "1  Mangaldoi - Afflux Bund at Noanadi Kachia Bund...  \n",
       "0  Gohpur - Dubia River Embankments is breached f...  \n",
       "0  Nowboicha - Breached occurred at Singra River ...  \n",
       "0  Matia - Dohapara Bamunpara Bandh | Bamunpara |...  \n",
       "0  Narayanpur - Farm bundh L/S-175 m R/S-175 m | ...  \n",
       "1  Harisinga - No. 2 Singrimari Suklai river emba...  \n",
       "2  Chariduar - 1 no embankment breached on DTD 17...  \n",
       "0  Mangaldoi - Approach Road in Noanadi Kachia Bu...  \n",
       "1  Kampur - Premajaan Embankment at Saibuk Gaon |...  \n",
       "3  Kalaigaon - Embankment at Majarchuba in the L/...  \n",
       "0  Harisinga - Dahalahabi embankment | Dahalahabi...  \n",
       "0  Barama - Breach occurred on L/B of Mora Paglad...  \n",
       "1  Tihu - ROAD CUM EMBANMENT,R/B MORA PAGOLDIA RI...  \n",
       "2  Mangaldoi - Breached at u/s afflux bund cum ro...  \n",
       "0  Bajali - Pahumara river breached at left bank ...  \n",
       "1  Gohpur - Chatrang river R/Bank embankment brea...  \n",
       "3  Nalbari - Pagaldia river at Nalbari sonkuriha ...  \n",
       "0  Gohpur - Chatrang P&R D Bund | At L/Bank or Ri...  \n",
       "0  Mangaldoi - CM Dutta | At village Mollapara | ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FRIMS_DAMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7ad6002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data_2023/Scraped Data/FRIMS_EMBANKMENTS_BREACHED/FRIMS_EMBANKMENTS_BREACHED_21-06-2023.csv',\n",
       " 'Data_2023/Scraped Data/FRIMS_EMBANKMENTS_BREACHED/FRIMS_EMBANKMENTS_BREACHED_15-06-2023.csv',\n",
       " 'Data_2023/Scraped Data/FRIMS_EMBANKMENTS_BREACHED/FRIMS_EMBANKMENTS_BREACHED_16-06-2023.csv',\n",
       " 'Data_2023/Scraped Data/FRIMS_EMBANKMENTS_BREACHED/FRIMS_EMBANKMENTS_BREACHED_23-06-2023.csv',\n",
       " 'Data_2023/Scraped Data/FRIMS_EMBANKMENTS_BREACHED/FRIMS_EMBANKMENTS_BREACHED_11-06-2023.csv',\n",
       " 'Data_2023/Scraped Data/FRIMS_EMBANKMENTS_BREACHED/FRIMS_EMBANKMENTS_BREACHED_20-06-2023.csv',\n",
       " 'Data_2023/Scraped Data/FRIMS_EMBANKMENTS_BREACHED/FRIMS_EMBANKMENTS_BREACHED_17-06-2023.csv',\n",
       " 'Data_2023/Scraped Data/FRIMS_EMBANKMENTS_BREACHED/FRIMS_EMBANKMENTS_BREACHED_25-06-2023.csv',\n",
       " 'Data_2023/Scraped Data/FRIMS_EMBANKMENTS_BREACHED/FRIMS_EMBANKMENTS_BREACHED_14-06-2023.csv',\n",
       " 'Data_2023/Scraped Data/FRIMS_EMBANKMENTS_BREACHED/FRIMS_EMBANKMENTS_BREACHED_12-06-2023.csv',\n",
       " 'Data_2023/Scraped Data/FRIMS_EMBANKMENTS_BREACHED/FRIMS_EMBANKMENTS_BREACHED_22-06-2023.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_files_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c38154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
